{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-31T20:45:46.008216Z",
     "start_time": "2025-01-31T20:45:45.990536Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "from jupyterlab.commands import build\n",
    "\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T20:45:48.054877Z",
     "start_time": "2025-01-31T20:45:46.100046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.graph import StateGraph,END\n",
    "from typing import TypedDict, Annotated,List\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, HumanMessage, AIMessage, SystemMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ],
   "id": "c1ebfde8abf797f1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T20:45:48.280078Z",
     "start_time": "2025-01-31T20:45:48.275479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AgentState(TypedDict):\n",
    "    task:str\n",
    "    plan:str\n",
    "    draft:str\n",
    "    critique:str\n",
    "    content: List[str]\n",
    "    revision_number:int\n",
    "    max_revisions:int"
   ],
   "id": "ec54d5b93f38f6da",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T20:45:48.837269Z",
     "start_time": "2025-01-31T20:45:48.290866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(temperature=0, model='gpt-3.5-turbo')"
   ],
   "id": "fe8e86e6c753a7c7",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T20:45:48.850047Z",
     "start_time": "2025-01-31T20:45:48.846655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PLAN_PROMPT = \"\"\"You are an expert writer tasked with writing a high level outline of an essay. \\\n",
    "Write such an outline for the user provided topic. Give an outline of the essay along with any relevant notes \\\n",
    "or instructions for the sections.\"\"\""
   ],
   "id": "9b0aa96f251ca36d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T20:45:48.862353Z",
     "start_time": "2025-01-31T20:45:48.857795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "WRITER_PROMPT = \"\"\"You are an essay assistant tasked with writing excellent 5-paragraph essays.\\\n",
    "Generate the best essay possible for the user's request and the initial outline. \\\n",
    "If the user provides critique, respond with a revised version of your previous attempts. \\\n",
    "Utilize all the information below as needed: \n",
    "\n",
    "------\n",
    "\n",
    "{content}\"\"\""
   ],
   "id": "2e640723d9502466",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T20:45:48.874828Z",
     "start_time": "2025-01-31T20:45:48.871737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "REFLECTION_PROMPT = \"\"\"You are a teacher grading an essay submission. \\\n",
    "Generate critique and recommendations for the user's submission. \\\n",
    "Provide detailed recommendations, including requests for length, depth, style, etc.\"\"\""
   ],
   "id": "46011db5e5265495",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T20:45:48.890289Z",
     "start_time": "2025-01-31T20:45:48.884575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "RESEARCH_PLAN_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when writing the following essay. Generate a list of search queries that will gather \\\n",
    "any relevant information. Only generate 3 queries max.\"\"\""
   ],
   "id": "9f2c5aed422d9793",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T20:45:48.913808Z",
     "start_time": "2025-01-31T20:45:48.909877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "RESEARCH_CRITIQUE_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when making any requested revisions (as outlined below). \\\n",
    "Generate a list of search queries that will gather any relevant information. Only generate 3 queries max.\"\"\""
   ],
   "id": "4466ee50f56056b2",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T20:45:48.930447Z",
     "start_time": "2025-01-31T20:45:48.926288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "class Queries(BaseModel):\n",
    "    queries: List[str]"
   ],
   "id": "440b6fe93380d6b1",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T20:45:48.977553Z",
     "start_time": "2025-01-31T20:45:48.966872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tavily import TavilyClient\n",
    "import os\n",
    "tavily = TavilyClient(os.environ[\"TAVILY_API_KEY\"])"
   ],
   "id": "13565a5a17d1da51",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T20:45:48.995824Z",
     "start_time": "2025-01-31T20:45:48.991364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#do plan\n",
    "def plan_node(state:AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=PLAN_PROMPT),\n",
    "        HumanMessage(content=state['task']),\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"plan\":response.content}"
   ],
   "id": "a4bfcff557fd1004",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T20:45:49.019137Z",
     "start_time": "2025-01-31T20:45:49.015019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#initial research\n",
    "def research_plan_node(state:AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_PLAN_PROMPT),\n",
    "        HumanMessage(content=state['task']),\n",
    "    ])\n",
    "    content = state[\"content\"] or []\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response['results']:\n",
    "            content.append(r['content'])\n",
    "    return {\"content\":content}"
   ],
   "id": "49cd911990d86d9e",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T20:45:49.047678Z",
     "start_time": "2025-01-31T20:45:49.042590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#do first draft\n",
    "def generation_node(state:AgentState):\n",
    "    content = \"\\n\\n\".join(state['content'] or [])\n",
    "    user_message = HumanMessage(\n",
    "        content=f\"{state[\"task\"]}\\n\\nHere is my plan:\\n\\n{state[\"plan\"]}\"\n",
    "    )\n",
    "    messages = [SystemMessage(content=WRITER_PROMPT.format(content=content)),\n",
    "                            user_message]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"draft\":response.content, \"revision_number\":state.get(\"revision_number\", 1)+1}"
   ],
   "id": "1e8b984ac5bd0e60",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T20:45:49.062974Z",
     "start_time": "2025-01-31T20:45:49.058778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#find critiques\n",
    "def reflecion_node(state:AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=REFLECTION_PROMPT),\n",
    "        HumanMessage(content=state['draft']),\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"critique\":response.content}"
   ],
   "id": "21045f77206055d9",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T20:45:49.078458Z",
     "start_time": "2025-01-31T20:45:49.072900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#second search\n",
    "def research_critique_node(state: AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_CRITIQUE_PROMPT),\n",
    "        HumanMessage(content=state['critique'])\n",
    "    ])\n",
    "    content = state['content'] or []\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response['results']:\n",
    "            content.append(r['content'])\n",
    "    return {\"content\": content}"
   ],
   "id": "298ee5071aceb411",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T20:45:49.106420Z",
     "start_time": "2025-01-31T20:45:49.100388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def should_continue(state:AgentState):\n",
    "    if state[\"revision_number\"] > state[\"max_revisions\"]:\n",
    "        return END\n",
    "    return \"reflect\""
   ],
   "id": "97c3601a5b916544",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T20:45:49.132583Z",
     "start_time": "2025-01-31T20:45:49.128048Z"
    }
   },
   "cell_type": "code",
   "source": "builder = StateGraph(AgentState)",
   "id": "6cb0200dd9cfa44a",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T20:45:49.159411Z",
     "start_time": "2025-01-31T20:45:49.153486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "builder.add_node(\"planner\", plan_node)\n",
    "builder.add_node(\"generate\", generation_node)\n",
    "builder.add_node(\"reflect\", reflecion_node)\n",
    "builder.add_node(\"research_plan\", research_plan_node)\n",
    "builder.add_node(\"research_critique\", research_critique_node)"
   ],
   "id": "f570a53ef489c417",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T20:46:13.159014Z",
     "start_time": "2025-01-31T20:46:13.155040Z"
    }
   },
   "cell_type": "code",
   "source": "builder.set_entry_point(\"planner\")",
   "id": "21c728b599148be",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T20:47:03.310658Z",
     "start_time": "2025-01-31T20:47:03.304709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "builder.add_conditional_edges(\n",
    "    \"generate\",should_continue,\n",
    "    {\n",
    "        END:END,\n",
    "        \"reflect\":\"reflect\"\n",
    "    }\n",
    ")"
   ],
   "id": "a1188259ceecb698",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T20:48:50.925585Z",
     "start_time": "2025-01-31T20:48:50.920376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "builder.add_edge(\"planner\", \"research_plan\")\n",
    "builder.add_edge(\"research_plan\", \"generate\")\n",
    "builder.add_edge(\"reflect\", \"research_critique\")\n",
    "builder.add_edge(\"research_critique\", \"generate\")"
   ],
   "id": "43bc0d595a3256d7",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T20:49:46.291275Z",
     "start_time": "2025-01-31T20:49:46.285386Z"
    }
   },
   "cell_type": "code",
   "source": "graph = builder.compile(checkpointer=memory)",
   "id": "77b80f517692277a",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "graph.get_graph().draw_mermaid_png(output_file_path='essay_writing_graph.png')",
   "id": "38f86cd204850b9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T20:55:02.932058Z",
     "start_time": "2025-01-31T20:54:23.840925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for s in graph.stream({\n",
    "    'task': \"what is the difference between langchain and langsmith\",\n",
    "    \"max_revisions\": 2,\n",
    "    \"revision_number\": 1,\n",
    "}, thread):\n",
    "    print(s)"
   ],
   "id": "c869206ca3e4ca2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'planner': {'plan': 'I. Introduction\\n    A. Brief overview of Langchain and Langsmith\\n    B. Thesis statement: Exploring the differences between Langchain and Langsmith\\n\\nII. Langchain\\n    A. Definition and explanation\\n    B. Key features and characteristics\\n    C. Use cases and applications\\n    D. Advantages and disadvantages\\n\\nIII. Langsmith\\n    A. Definition and explanation\\n    B. Key features and characteristics\\n    C. Use cases and applications\\n    D. Advantages and disadvantages\\n\\nIV. Comparison between Langchain and Langsmith\\n    A. Technology stack\\n    B. Scalability\\n    C. Security\\n    D. Performance\\n    E. Adoption and popularity\\n\\nV. Conclusion\\n    A. Recap of main differences between Langchain and Langsmith\\n    B. Implications for the future of blockchain technology\\n    C. Final thoughts and recommendations\\n\\nNotes:\\n- Ensure to provide clear definitions and explanations of both Langchain and Langsmith.\\n- Include specific examples of real-world applications for each technology.\\n- Use data and statistics to support the comparison between the two technologies.\\n- Conclude with insights on the potential impact of Langchain and Langsmith on the blockchain industry.'}}\n",
      "{'research_plan': {'content': ['Here’s the deal: LangChain is like building the entire car, while LangSmith is your diagnostic tool to ensure that car runs smoothly. When it comes to practical application, I always say: “Show, don’t tell.” I’ve used both LangChain and LangSmith extensively, and I’ve found that they complement each other beautifully when you’re building and fine-tuning LLM-based workflows. Having spent countless hours building and debugging LLM-based systems, I’ve learned that using LangChain and LangSmith effectively requires a few smart strategies. I often use LangChain to build my pipelines and LangSmith to monitor and debug them. Start with LangChain to build your pipeline, and then bring in LangSmith to ensure it performs as expected.', 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while Langchain excels at managing and scaling model workflows, Langsmith is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a complex AI pipeline with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, Langsmith’s advanced debugging and orchestration features will be indispensable. Additionally, if you’re working on cross-platform model deployments — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.', 'Data Structures and Algorithms\\nML & Data Science\\nWeb Development\\nLanguages\\nInterview Corner\\nCS Subjects\\nJobs\\nPractice\\nContests\\nIntroduction to Langchain\\nLangChain is an open-source framework designed to simplify the creation of applications using large language models (LLMs). LangChain follows a general pipeline where a user asks a question to the language model where the vector representation of the question is used to do a similarity search in the vector database and the relevant information is fetched from the vector database and the response is later fed to the language model. LangChain Key Concepts:\\nThe main properties of LangChain Framework are :\\nSetting up the environment\\nInstallation of langchain is very simple and similar as you install other libraries using the pip command.\\n Next, we create a .env file and store our API key in it as follows:\\nPython\\nNow, I am creating a new file named ‘lang.py’ where I will be using the LangChain framework to generate responses. We start by importing long-chain and initializing an LLM as follows:\\nPython\\nWe are initializing it with a high temperature which means that the results will be random and less accurate.', \"How to use tools in a chain How to migrate from legacy LangChain agents to LangGraph How to use chat models to call tools LangChain is a framework for developing applications powered by large language models (LLMs). Development: Build your applications using LangChain's open-source building blocks, components, and third-party integrations. langchain: Chains, agents, and retrieval strategies that make up an application's cognitive architecture. LangServe: Deploy LangChain chains as REST APIs. LangSmith: A developer platform that lets you debug, test, evaluate, and monitor LLM applications. Build stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. LangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it.\", 'Langsmith is an innovative framework designed to enhance and streamline the development of natural language processing (NLP) applications. It builds upon LangChain, a popular library for chaining multiple language models together, to create sophisticated and flexible NLP workflows. Langsmith provides tools for managing, deploying, and scaling', 'ClickHouse . ClickHouse is a high-performance, column-oriented SQL database management system (DBMS) for online analytical processing (OLAP).. LangSmith uses ClickHouse as the primary data store for traces and feedback (high-volume data). PostgreSQL . PostgreSQL is a powerful, open source object-relational database system that uses and extends the SQL language combined with many features that']}}\n",
      "{'generate': {'draft': \"**Essay: Exploring the Differences Between LangChain and LangSmith**\\n\\nI. **Introduction**\\n\\nLangChain and LangSmith are two innovative frameworks designed to enhance the development of applications using large language models (LLMs). While both tools serve the purpose of working with LLMs, they have distinct functionalities that cater to different aspects of the development process. This essay aims to delve into the disparities between LangChain and LangSmith to provide a comprehensive understanding of their unique features and applications.\\n\\nII. **LangChain**\\n\\nLangChain is an open-source framework tailored to simplify the creation of applications utilizing large language models. It follows a structured pipeline where user queries are processed through a language model, enabling similarity searches in a vector database to retrieve relevant information. Key features of LangChain include easy environment setup, simple installation process, and the ability to generate responses using LLMs with varying levels of accuracy. Real-world applications of LangChain span across various domains such as data structures and algorithms, ML & data science, web development, and more. While LangChain offers a straightforward approach to building applications with LLMs, its main disadvantage lies in the potential accuracy trade-off when using high-temperature settings.\\n\\nIII. **LangSmith**\\n\\nOn the other hand, LangSmith serves as a diagnostic tool aimed at ensuring the smooth operation of applications built with LLMs. It provides deep visibility and control over complex AI systems in production, making it an essential tool for debugging and monitoring pipelines. LangSmith's advanced debugging and orchestration features are particularly valuable when managing intricate AI models or large-scale workflows with multiple components. Moreover, LangSmith excels in handling cross-platform model deployments, offering superior orchestration and monitoring tools to manage the complexity effectively.\\n\\nIV. **Comparison between LangChain and LangSmith**\\n\\nA. **Technology Stack**: LangChain focuses on simplifying the creation of applications using LLMs, while LangSmith emphasizes monitoring and debugging complex AI systems.\\nB. **Scalability**: LangChain excels in managing and scaling model workflows, whereas LangSmith is designed for deep visibility and control over large, complex AI systems.\\nC. **Security**: Both LangChain and LangSmith prioritize data security, with LangSmith utilizing ClickHouse as the primary data store for high-volume data.\\nD. **Performance**: LangChain is ideal for building pipelines, while LangSmith is essential for monitoring and debugging these pipelines effectively.\\nE. **Adoption and Popularity**: LangChain is widely used for developing applications with LLMs, while LangSmith's popularity stems from its advanced debugging and orchestration features.\\n\\nV. **Conclusion**\\n\\nIn conclusion, LangChain and LangSmith play complementary roles in the development and maintenance of applications powered by large language models. While LangChain focuses on building and scaling workflows, LangSmith ensures the operational efficiency and performance of these applications. Understanding the nuances between LangChain and LangSmith is crucial for leveraging their capabilities effectively and optimizing the development process in the evolving landscape of AI technologies.\", 'revision_number': 2}}\n",
      "{'reflect': {'critique': \"**Critique:**\\n\\nThe essay provides a clear overview of LangChain and LangSmith, highlighting their key features and applications. The introduction effectively sets the stage for the comparison between the two frameworks, and the subsequent sections delve into the specifics of each tool. The comparison between LangChain and LangSmith in terms of technology stack, scalability, security, performance, and adoption is informative and helps in understanding the distinct functionalities of each framework.\\n\\n**Recommendations:**\\n\\n1. **Depth and Analysis:** While the essay provides a good overview of LangChain and LangSmith, it would benefit from a deeper analysis of their strengths and weaknesses. For instance, providing specific examples of real-world applications where each framework excels would enhance the understanding of their practical utility.\\n\\n2. **Detailed Examples:** Incorporating case studies or use cases where LangChain and LangSmith have been successfully implemented would add depth to the comparison. This would help readers visualize how each framework can be applied in different scenarios.\\n\\n3. **Expansion on Disadvantages:** The essay briefly mentions the potential accuracy trade-off with LangChain when using high-temperature settings. Expanding on this point and discussing any other limitations or challenges faced by both frameworks would provide a more balanced view of their capabilities.\\n\\n4. **Recommendation for Usage:** Including a section that outlines scenarios where one framework might be more suitable than the other would be beneficial. This could help readers understand the criteria for selecting between LangChain and LangSmith based on specific project requirements.\\n\\n5. **Conclusion:** The conclusion could be strengthened by summarizing the key points of differentiation between LangChain and LangSmith and reiterating the importance of understanding these differences for effective utilization of both frameworks.\\n\\n6. **Length:** Consider expanding on each framework's features, functionalities, and practical applications to provide a more comprehensive comparison. Aim for a more detailed exploration of the nuances between LangChain and LangSmith to offer a richer analysis.\\n\\nOverall, the essay presents a solid foundation for comparing LangChain and LangSmith. By incorporating more detailed examples, expanding on disadvantages, and providing practical recommendations for usage, the essay can offer a more thorough understanding of the unique characteristics of each framework.\"}}\n",
      "{'research_critique': {'content': ['Here’s the deal: LangChain is like building the entire car, while LangSmith is your diagnostic tool to ensure that car runs smoothly. When it comes to practical application, I always say: “Show, don’t tell.” I’ve used both LangChain and LangSmith extensively, and I’ve found that they complement each other beautifully when you’re building and fine-tuning LLM-based workflows. Having spent countless hours building and debugging LLM-based systems, I’ve learned that using LangChain and LangSmith effectively requires a few smart strategies. I often use LangChain to build my pipelines and LangSmith to monitor and debug them. Start with LangChain to build your pipeline, and then bring in LangSmith to ensure it performs as expected.', 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while Langchain excels at managing and scaling model workflows, Langsmith is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a complex AI pipeline with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, Langsmith’s advanced debugging and orchestration features will be indispensable. Additionally, if you’re working on cross-platform model deployments — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.', 'Data Structures and Algorithms\\nML & Data Science\\nWeb Development\\nLanguages\\nInterview Corner\\nCS Subjects\\nJobs\\nPractice\\nContests\\nIntroduction to Langchain\\nLangChain is an open-source framework designed to simplify the creation of applications using large language models (LLMs). LangChain follows a general pipeline where a user asks a question to the language model where the vector representation of the question is used to do a similarity search in the vector database and the relevant information is fetched from the vector database and the response is later fed to the language model. LangChain Key Concepts:\\nThe main properties of LangChain Framework are :\\nSetting up the environment\\nInstallation of langchain is very simple and similar as you install other libraries using the pip command.\\n Next, we create a .env file and store our API key in it as follows:\\nPython\\nNow, I am creating a new file named ‘lang.py’ where I will be using the LangChain framework to generate responses. We start by importing long-chain and initializing an LLM as follows:\\nPython\\nWe are initializing it with a high temperature which means that the results will be random and less accurate.', \"How to use tools in a chain How to migrate from legacy LangChain agents to LangGraph How to use chat models to call tools LangChain is a framework for developing applications powered by large language models (LLMs). Development: Build your applications using LangChain's open-source building blocks, components, and third-party integrations. langchain: Chains, agents, and retrieval strategies that make up an application's cognitive architecture. LangServe: Deploy LangChain chains as REST APIs. LangSmith: A developer platform that lets you debug, test, evaluate, and monitor LLM applications. Build stateful, multi-actor applications with LLMs. Integrates smoothly with LangChain, but can be used without it. LangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it.\", 'Langsmith is an innovative framework designed to enhance and streamline the development of natural language processing (NLP) applications. It builds upon LangChain, a popular library for chaining multiple language models together, to create sophisticated and flexible NLP workflows. Langsmith provides tools for managing, deploying, and scaling', 'ClickHouse . ClickHouse is a high-performance, column-oriented SQL database management system (DBMS) for online analytical processing (OLAP).. LangSmith uses ClickHouse as the primary data store for traces and feedback (high-volume data). PostgreSQL . PostgreSQL is a powerful, open source object-relational database system that uses and extends the SQL language combined with many features that', 'LangChain and LangSmith are two complementary tools that cater to different stages and requirements of LLM development. LangChain is ideal for early-stage prototyping and small-scale applications, while LangSmith is better suited for large-scale, production-ready applications that require advanced debugging, testing, and monitoring capabilities', 'If you’re responsible for ensuring your AI models work in production, or you need to frequently debug and monitor your pipelines, Langsmith is your go-to tool. In short, while Langchain excels at managing and scaling model workflows, Langsmith is designed for those times when you need deep visibility and control over large, complex AI systems in production. But if you’re managing a complex AI pipeline with multiple models that need debugging and orchestrating, Langsmith’s capabilities become essential. If you’re debugging complex AI models or managing large-scale workflows with multiple moving parts, Langsmith’s advanced debugging and orchestration features will be indispensable. Additionally, if you’re working on cross-platform model deployments — say, running models on-prem and in the cloud simultaneously — Langsmith offers better orchestration and monitoring tools to handle the complexity.', 'Here’s the deal: LangChain is like building the entire car, while LangSmith is your diagnostic tool to ensure that car runs smoothly. When it comes to practical application, I always say: “Show, don’t tell.” I’ve used both LangChain and LangSmith extensively, and I’ve found that they complement each other beautifully when you’re building and fine-tuning LLM-based workflows. Having spent countless hours building and debugging LLM-based systems, I’ve learned that using LangChain and LangSmith effectively requires a few smart strategies. I often use LangChain to build my pipelines and LangSmith to monitor and debug them. Start with LangChain to build your pipeline, and then bring in LangSmith to ensure it performs as expected.', \"Focus on Production-Readiness: Langsmith's tools are geared towards creating LLM applications robust enough for real-world use. It helps developers ensure their applications are reliable and high-quality . Monitoring and Evaluation: Langsmith provides features to closely monitor how your LLM application performs. This allows you to identify\", 'LangChain and LangSmith are two complementary tools that cater to different stages and requirements of LLM development. LangChain is ideal for early-stage prototyping and small-scale applications, while LangSmith is better suited for large-scale, production-ready applications that require advanced debugging, testing, and monitoring capabilities.', \"This paper provides an in-depth analysis of LangChain's architecture and core components, including LangGraph, LangServe, and LangSmith. We explore how the framework facilitates the development of LLM applications, discuss its applications across multiple domains, and critically evaluate its limitations in terms of usability, security, and\"]}}\n",
      "{'generate': {'draft': \"**Essay:**\\n\\n**I. Introduction**\\n\\nLangChain and LangSmith are two essential tools in the realm of large language model (LLM) development. LangChain serves as a framework for building applications using LLMs, while LangSmith is a diagnostic tool designed to enhance the development and monitoring of natural language processing (NLP) applications. This essay aims to delve into the disparities between LangChain and LangSmith.\\n\\n**II. LangChain**\\n\\nLangChain is an open-source framework tailored to simplify the creation of applications utilizing LLMs. It follows a structured pipeline where a user queries the language model, conducts a similarity search in the vector database, and retrieves relevant information. Key features of LangChain include easy installation, setting up the environment, and the ability to build applications using its building blocks and third-party integrations. While LangChain is ideal for early-stage prototyping and small-scale applications, it may lack the advanced debugging and monitoring capabilities required for large-scale production-ready systems.\\n\\n**III. LangSmith**\\n\\nLangSmith, on the other hand, is an innovative framework that builds upon LangChain to streamline the development of NLP applications. It provides tools for managing, deploying, and scaling LLM workflows. LangSmith utilizes ClickHouse as the primary data store for traces and feedback, enhancing its capabilities for monitoring and evaluation. This tool is indispensable for debugging complex AI models and orchestrating large-scale workflows with multiple moving parts.\\n\\n**IV. Comparison between LangChain and LangSmith**\\n\\n- *Technology Stack*: LangChain focuses on simplifying the creation of LLM applications, while LangSmith enhances the development and monitoring of NLP applications.\\n- *Scalability*: LangChain is suitable for early-stage prototyping and small-scale applications, whereas LangSmith is better equipped for large-scale, production-ready systems.\\n- *Security*: Both tools prioritize security, but LangSmith's advanced monitoring features contribute to creating more robust and reliable applications.\\n- *Performance*: LangChain aids in building pipelines, while LangSmith excels in monitoring, debugging, and orchestrating complex AI systems.\\n- *Adoption and Popularity*: LangChain is widely used for prototyping, while LangSmith gains popularity for its advanced debugging and monitoring capabilities.\\n\\n**V. Conclusion**\\n\\nIn conclusion, LangChain and LangSmith play distinct roles in the development of LLM applications. While LangChain is instrumental in building applications, LangSmith enhances the monitoring and debugging processes. Understanding the differences between these tools is crucial for developers aiming to create efficient and reliable LLM-based systems. The future of blockchain technology will undoubtedly be influenced by the continued evolution and integration of tools like LangChain and LangSmith.\", 'revision_number': 3}}\n"
     ]
    }
   ],
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
